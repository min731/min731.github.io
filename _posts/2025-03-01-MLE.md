---
title: "MLE (Maximum Likelihood Estimation)"
# author:
#   name: Joung min Lim
#   link: https://github.com/min731
date: 2025-03-01 00:00:00 +0900
categories: [STEM | ìˆ˜í•™/í†µê³„, Statistics]
# categories: [AI ; ë…¼ë¬¸ ë¦¬ë·°, Attention is all you need]
# categories: [MLOps ; ì¸í”„ë¼ ê°œë°œ, Kserve]
# categories: [Life ; ì¼ìƒ ì´ì•¼ê¸°, ì™€í”Œë¨¹ìœ¼ë©´ì„œ ê³µë¶€í•˜ê¸°]
tags: [DeepLearning, MLE, ìµœëŒ€ìš°ë„ë²•]
description: "MLE (Maximum Likelihood Estimation) ëŒ€í•´ ì•Œì•„ë´…ì‹œë‹¤."
image: assets/img/posts/resize/output/Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg.png # ëŒ€í‘œ ì´ë¯¸ì§€  ê°€ë¡œ ì„¸ë¡œ ë¹„ìœ¨ ì•½ 1.91:1 (ì˜ˆ: 1200Ã—628px)
math: true
toc: true
# pin: true
---

<div align="center">
  <small>Source: <a href="https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg">https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg</a></small>
</div>

>  *ë³¸ ê²Œì‹œê¸€ì€ ìœ íŠœë¸Œ ['ê³µëŒì´ì˜ ìˆ˜í•™ì •ë¦¬ë…¸íŠ¸' ìµœëŒ€ìš°ë„ë²•(Maximum Likelihood Estimation) ì†Œê°œ](https://www.youtube.com/watch?v=XhlfVtGb19c), ë¸”ë¡œê·¸ ['ê³µëŒì´ì˜ ìˆ˜í•™ì •ë¦¬ë…¸íŠ¸' ìµœëŒ€ìš°ë„ë²•(MLE)](https://angeloyeo.github.io/2020/07/17/MLE.html) ìë£Œë¥¼ ì°¸ê³ í•œ ì ì„ì„ ì•Œë¦½ë‹ˆë‹¤.

## MLE (Maximum Likelihood Estimation)

### 1. ì •ì˜

MLEì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ì£¼ì–´ì§„ ë°ì´í„° ì§‘í•© $$X = \{x_1, x_2, ...,x_n\}$$ì— ëŒ€í•´, ì´ ë°ì´í„°ê°€ íŠ¹ì • í™•ë¥  ë¶„í¬ì—ì„œ ë‚˜ì™”ë‹¤ê³  ê°€ì •í•  ë•Œ, ê·¸ í™•ë¥  ë¶„í¬ì˜ íŒŒë¼ë¯¸í„° $$\theta$$ ì¶”ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë•Œ ìš°ë¦¬ëŠ” ë‹¤ìŒì˜ ìš°ë„(likelihood) í•¨ìˆ˜$$L(\theta; \mathbf{X})$$ë¥¼ ìµœëŒ€í™”í•˜ëŠ” $$\theta$$ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

### 2. ìš°ë„ í•¨ìˆ˜ (Likelihood Function)

ìš°ë„ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„° $$\theta$$ í•˜ì—ì„œ ë°ì´í„° $$ğ‘‹$$ê°€ ê´€ì°°ë  í™•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë©ë‹ˆë‹¤.

$$
L(\theta; \mathbf{X}) = P(\mathbf{X} ; \theta)
$$

ìœ„ ìˆ˜ì‹ì—ì„œ $$P(\mathbf{X};\theta)$$ëŠ” íŒŒë¼ë¯¸í„° $$\theta$$í•˜ì—ì„œ ë°ì´í„° $$X$$ê°€ ê´€ì°°ë  í™•ë¥ ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ë§Œì•½ ê° ë°ì´í„° $$x_i$$ê°€ ë…ë¦½ì ì´ê³  ë™ì¼í•œ ë¶„í¬(Identically Distributed)ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•˜ë©´, ìš°ë„ í•¨ìˆ˜ëŠ” ê°œë³„ ë°ì´í„°ê°€ ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„°ì—ì„œ ë°œìƒí•  í™•ë¥ ì˜ ê³±ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$
L(\theta; \mathbf{X}) = \prod_{i=1}^{n} P(x_i ; \theta)
$$

$$
(ë…ë¦½ì ì¸\ ë°ì´í„°ì¼\ ê²½ìš°)
$$

### 3. ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ (Log-Likelihood Function)

ìš°ë„ í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì€ ê³„ì‚°ì ìœ¼ë¡œ ë³µì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë¡œê·¸ë¥¼ ì·¨í•œ ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë©ë‹ˆë‹¤.

$$
\ell(\theta; \mathbf{X}) = \log L(\theta; \mathbf{X}) = \sum_{i=1}^{n} \log P(x_i ; \theta)
$$

ë¡œê·¸ë¥¼ ì·¨í•´ë„ ìµœì í™” ë¬¸ì œëŠ” ë³€í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, MLE ë¬¸ì œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë³€í™˜ë©ë‹ˆë‹¤.

$$
\hat{\theta} = \arg\max_{\theta} \ell(\theta; \mathbf{X})
$$

### 4. MLEì˜ ì¦ëª…

MLEëŠ” ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ $$\ell(\theta; \mathbf{X})$$ë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„° $$\theta$$ë¥¼ ì°¾ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ì€ ì ˆì°¨ë¥¼ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.

#### ì ˆì°¨

(1) ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ì˜ ë¯¸ë¶„: ë¨¼ì € ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ $$\ell(\theta; \mathbf{X})$$ë¥¼ íŒŒë¼ë¯¸í„° $$\theta$$ì— ëŒ€í•´ ë¯¸ë¶„í•©ë‹ˆë‹¤.

$$ 
\frac{\partial \ell}{\partial \theta} 
$$ 

(2) ìµœëŒ€ê°’ì„ ì°¾ê¸° ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ì´ ë¯¸ë¶„ ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ 
$$\theta$$ì— ëŒ€í•œ ë°©ì •ì‹ì„ ë§Œë“­ë‹ˆë‹¤.

$$ 
\frac{\partial \ell}{\partial \theta} = 0 
$$

(3) íŒŒë¼ë¯¸í„° $$\theta$$ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤. ì´ ë°©ì •ì‹ì„ í’€ì–´ ìµœì ì˜ $$\theta$$ ê°’ì„ êµ¬í•©ë‹ˆë‹¤.

#### ì •ê·œ ë¶„í¬ì—ì„œì˜ MLE

ì •ê·œë¶„í¬ë¥¼ ì˜ˆë¡œ ë“¤ì–´ ì„¤ëª…í•´ë³´ê² ìŠµë‹ˆë‹¤. ë°ì´í„° $$X = \{x_1, x_2, ...,x_n\}$$ê°€ í‰ê·  $$\mu$$ì™€ ë¶„ì‚° $$\sigma^2$$ë¥¼ ê°–ëŠ” ì •ê·œë¶„í¬$$
\mathcal{N}(\mu, \sigma^2)$$ì—ì„œ ë‚˜ì™”ë‹¤ê³  ê°€ì •í•©ì‹œë‹¤. ì´ë•Œ, ê° ë°ì´í„° $$x_i$$ì˜ í™•ë¥  ë°€ë„ í•¨ìˆ˜(PDF)ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

$$
P(x_i ; \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
$$

ìš°ë„ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„° $$\theta = (\mu,\sigma^2)$$ì—ì„œ ê´€ì°°ëœ ë°ì´í„° $$ğ‘‹$$ê°€ ë°œìƒí•  í™•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë°ì´í„°ê°€ ë…ë¦½ì ìœ¼ë¡œ ë°œìƒí–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ì „ì²´ ìš°ë„ í•¨ìˆ˜ $$L(\mu,\sigma^2;X)$$ëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ í™•ë¥  ë°€ë„ í•¨ìˆ˜ì˜ ê³±ìœ¼ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.

$$
L(\mu, \sigma^2; \mathbf{X}) = \prod_{i=1}^{n} P(x_i ; \mu, \sigma^2)
$$

ì´ë¥¼ ì •ê·œë¶„í¬ì˜ í™•ë¥  ë°€ë„ í•¨ìˆ˜ë¡œ ëŒ€ì²´í•˜ë©´,

$$
L(\mu, \sigma^2; \mathbf{X}) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
$$

ìš°ë„ í•¨ìˆ˜ë¥¼ ì§ì ‘ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì€ ê³±ì…ˆìœ¼ë¡œ ì¸í•´ ë³µì¡í•˜ë¯€ë¡œ, ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ë¡œê·¸ë¥¼ ì·¨í•˜ë©´ ê³±ì…ˆì´ ë§ì…ˆìœ¼ë¡œ ë°”ë€ë‹ˆë‹¤.

$$
\ell(\mu, \sigma^2; \mathbf{X}) = \log L(\mu, \sigma^2; \mathbf{X}) = \sum_{i=1}^{n} \log \left[\frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)\right]
$$

$$
\ell(\mu, \sigma^2; \mathbf{X}) = \sum_{i=1}^{n} \left[\log \frac{1}{\sqrt{2\pi\sigma^2}} + \log \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)\right]
$$


$$
\ell(\mu, \sigma^2; \mathbf{X}) = \sum_{i=1}^{n} \left[-\frac{1}{2} \log(2\pi\sigma^2) - \frac{(x_i - \mu)^2}{2\sigma^2}\right]
$$

$$ 
\ell(\mu, \sigma^2; \mathbf{X}) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2
$$

ì´ì œ ì´ ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ë¥¼ ì›í•˜ëŠ” íŒŒë¼ë¯¸í„° $$\theta$$ ($$\mu$$, $$\sigma^2$$)ì— ëŒ€í•´ ìµœëŒ€í™”í•˜ëŠ” ê°’ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.

#### (1) í‰ê·  $$\mu$$ì— ëŒ€í•´ ìµœì í™”

ë¨¼ì €, ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ $$\ell(\mu, \sigma^2; \mathbf{X})$$ë¥¼ $$\mu$$ì— ëŒ€í•´ ë¯¸ë¶„í•œ í›„, ì´ ê°’ì„ 0ìœ¼ë¡œ ë†“ì•„ ìµœì ì˜ $$\mu$$ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ë¥¼ $$\mu$$ì— ëŒ€í•´ ë¯¸ë¶„í•©ë‹ˆë‹¤.

$$
\frac{\partial \ell}{\partial \mu} = \frac{\partial}{\partial \mu} \left[ -\frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2 \right]
$$

ì´ì œ ë¯¸ë¶„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

$$
\frac{\partial \ell}{\partial \mu} = -\frac{1}{2\sigma^2} \cdot \left(-2 \sum_{i=1}^{n} (x_i - \mu)\right) = \frac{1}{\sigma^2} \sum_{i=1}^{n} (x_i - \mu)
$$

ì´ ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìµœì ì˜ $$\mu$$ë¥¼ êµ¬í•©ë‹ˆë‹¤.

$$
\frac{1}{\sigma^2} \sum_{i=1}^{n} (x_i - \mu) = 0
$$

ì´ë¥¼ í’€ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.

$$
\sum_{i=1}^{n} (x_i - \mu) = 0 \quad \Rightarrow \quad \mu = \frac{1}{n} \sum_{i=1}^{n} x_i
$$

ë”°ë¼ì„œ, MLEë¡œ ì¶”ì •ëœ í‰ê·  $$\hat{\mu}$$ëŠ” ì£¼ì–´ì§„ ë°ì´í„°ì˜ í‰ê· ì…ë‹ˆë‹¤.

#### (2) ë¶„ì‚° $$\sigma^2$$ì— ëŒ€í•´ ìµœì í™”

ì´ì œ ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ë¥¼ $$\sigma^2$$ì— ëŒ€í•´ ë¯¸ë¶„í•œ í›„, ì´ ê°’ì„ 0ìœ¼ë¡œ ë†“ì•„ ìµœì ì˜ $$\sigma^2$$ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ë¥¼ $$\sigma^2$$ì— ëŒ€í•´ ë¯¸ë¶„í•©ë‹ˆë‹¤.

$$
\frac{\partial \ell}{\partial \sigma^2} = \frac{\partial}{\partial \sigma^2} \left[-\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2 \right]
$$

ìš°í•­ì˜ ì²«ë²ˆì§¸ í•­ì—ì„œëŠ”

$$
\frac{\partial}{\partial \sigma^2} \left[-\frac{n}{2} \log(2\pi\sigma^2)\right] = -\frac{n}{2} \cdot \frac{1}{\sigma^2}
$$

ìš°í•­ì˜ ë‘ë²ˆì§¸ í•­ì—ì„œëŠ”

$$
\frac{\partial}{\partial \sigma^2} \left[- \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2\right] = \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2
$$

ë”°ë¼ì„œ, ì „ì²´ ë¯¸ë¶„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

$$
\frac{\partial \ell}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2
$$

ì´ë¥¼ 0ìœ¼ë¡œ ë†“ê³  ìµœì ì˜ $$\sigma^2$$ë¥¼ êµ¬í•©ë‹ˆë‹¤.

$$
-\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2 = 0
$$

ì´ ì‹ì„ í’€ë©´,

$$
\frac{n}{2\sigma^2} = \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2
$$


$$
n\sigma^2 = \sum_{i=1}^{n} (x_i - \mu)^2
$$

$$
\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2
$$

ë”°ë¼ì„œ, ìµœëŒ€ìš°ë„ì¶”ì •ë²•(MLE)ì„ í†µí•´ ì¶”ì •ëœ ë¶„ì‚° $$\sigma^2$$ëŠ” ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•´ ê° ë°ì´í„° í¬ì¸íŠ¸ì™€ í‰ê·  $$\mu$$ì˜ ì°¨ì´ì˜ ì œê³±ì˜ í‰ê· ìœ¼ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤.

### 5. ê²°ë¡ 

ì •ê·œë¶„í¬ì—ì„œ MLEë¥¼ ì‚¬ìš©í•´ í‰ê·  $$\mu$$ì™€ ë¶„ì‚° $$\sigma^2$$ë¥¼ ì¶”ì •í•˜ëŠ” ê³¼ì •ì—ì„œ, ìš°ë¦¬ëŠ” ë¡œê·¸ ìš°ë„ í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ ë¯¸ë¶„ì„ ìˆ˜í–‰í•˜ê³ , ì´ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìµœì ì˜ ê°’ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.

í‰ê·  $$\mu$$ëŠ” ë°ì´í„°ì˜ ì‚°ìˆ  í‰ê· ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤. ë¶„ì‚° $$\sigma^2$$ëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì™€ í‰ê·  ê°„ì˜ ì°¨ì´ ì œê³±ì˜ í‰ê· ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.

ì´ ê²°ê³¼ëŠ” ì •ê·œë¶„í¬ì˜ íŠ¹ì„±ê³¼ ì¼ì¹˜í•˜ë©°, MLEê°€ ë§¤ìš° ìœ ìš©í•œ íŒŒë¼ë¯¸í„° ì¶”ì • ë°©ë²•ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


> ì°¸ê³  ìë£Œ

- [https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg](https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg)
- ['ê³µëŒì´ì˜ ìˆ˜í•™ì •ë¦¬ë…¸íŠ¸' ìµœëŒ€ìš°ë„ë²•(Maximum Likelihood Estimation) ì†Œê°œ](https://www.youtube.com/watch?v=XhlfVtGb19c)
- ['ê³µëŒì´ì˜ ìˆ˜í•™ì •ë¦¬ë…¸íŠ¸' ìµœëŒ€ìš°ë„ë²•(MLE)](https://angeloyeo.github.io/2020/07/17/MLE.html)