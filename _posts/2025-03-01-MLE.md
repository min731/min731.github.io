---
title: "MLE (Maximum Likelihood Estimation)"
# author:
#   name: Joung min Lim
#   link: https://github.com/min731
date: 2025-03-01 00:00:00 +0900
categories: [STEM | 수학/통계, Statistics]
# categories: [AI ; 논문 리뷰, Attention is all you need]
# categories: [MLOps ; 인프라 개발, Kserve]
# categories: [Life ; 일상 이야기, 와플먹으면서 공부하기]
tags: [DeepLearning, MLE, 최대우도법]
description: "MLE (Maximum Likelihood Estimation) 대해 알아봅시다."
image: assets/img/posts/resize/output/Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg.png # 대표 이미지  가로 세로 비율 약 1.91:1 (예: 1200×628px)
math: true
toc: true
# pin: true
---

<div align="center">
  <small>Source: <a href="https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg">https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg</a></small>
</div>

>  *본 게시글은 유튜브 ['공돌이의 수학정리노트' 최대우도법(Maximum Likelihood Estimation) 소개](https://www.youtube.com/watch?v=XhlfVtGb19c), 블로그 ['공돌이의 수학정리노트' 최대우도법(MLE)](https://angeloyeo.github.io/2020/07/17/MLE.html) 자료를 참고한 점임을 알립니다.

## MLE (Maximum Likelihood Estimation)

### 1. 정의

MLE의 기본 아이디어는 주어진 데이터 집합 $$X = \{x_1, x_2, ...,x_n\}$$에 대해, 이 데이터가 특정 확률 분포에서 나왔다고 가정할 때, 그 확률 분포의 파라미터 $$\theta$$ 추정하는 것입니다. 이때 우리는 다음의 우도(likelihood) 함수$$L(\theta; \mathbf{X})$$를 최대화하는 $$\theta$$를 찾습니다.

### 2. 우도 함수 (Likelihood Function)

우도 함수는 주어진 파라미터 $$\theta$$ 하에서 데이터 $$𝑋$$가 관찰될 확률을 나타냅니다. 이 함수는 다음과 같이 정의됩니다.

$$
L(\theta; \mathbf{X}) = P(\mathbf{X} ; \theta)
$$

위 수식에서 $$P(\mathbf{X};\theta)$$는 파라미터 $$\theta$$하에서 데이터 $$X$$가 관찰될 확률을 의미합니다.

만약 각 데이터 $$x_i$$가 독립적이고 동일한 분포(Identically Distributed)를 따른다고 가정하면, 우도 함수는 개별 데이터가 주어진 파라미터에서 발생할 확률의 곱으로 나타낼 수 있습니다.

$$
L(\theta; \mathbf{X}) = \prod_{i=1}^{n} P(x_i ; \theta)
$$

$$
(독립적인\ 데이터일\ 경우)
$$

### 3. 로그 우도 함수 (Log-Likelihood Function)

우도 함수를 최대화하는 것은 계산적으로 복잡할 수 있으므로, 로그를 취한 로그 우도 함수를 사용하여 계산을 단순화합니다. 로그 우도 함수는 다음과 같이 정의됩니다.

$$
\ell(\theta; \mathbf{X}) = \log L(\theta; \mathbf{X}) = \sum_{i=1}^{n} \log P(x_i ; \theta)
$$

로그를 취해도 최적화 문제는 변하지 않으므로, MLE 문제는 다음과 같이 변환됩니다.

$$
\hat{\theta} = \arg\max_{\theta} \ell(\theta; \mathbf{X})
$$

### 4. MLE의 증명

MLE는 로그 우도 함수 $$\ell(\theta; \mathbf{X})$$를 최대화하는 파라미터 $$\theta$$를 찾는 문제입니다. 이 과정은 다음과 같은 절차를 통해 이루어집니다.

#### 절차

(1) 로그 우도 함수의 미분: 먼저 로그 우도 함수 $$\ell(\theta; \mathbf{X})$$를 파라미터 $$\theta$$에 대해 미분합니다.

$$ 
\frac{\partial \ell}{\partial \theta} 
$$ 

(2) 최대값을 찾기 위해 0으로 설정합니다. 이 미분 값을 0으로 설정하여 
$$\theta$$에 대한 방정식을 만듭니다.

$$ 
\frac{\partial \ell}{\partial \theta} = 0 
$$

(3) 파라미터 $$\theta$$를 추정합니다. 이 방정식을 풀어 최적의 $$\theta$$ 값을 구합니다.

#### 정규 분포에서의 MLE

정규분포를 예로 들어 설명해보겠습니다. 데이터 $$X = \{x_1, x_2, ...,x_n\}$$가 평균 $$\mu$$와 분산 $$\sigma^2$$를 갖는 정규분포$$
\mathcal{N}(\mu, \sigma^2)$$에서 나왔다고 가정합시다. 이때, 각 데이터 $$x_i$$의 확률 밀도 함수(PDF)는 다음과 같습니다.

$$
P(x_i ; \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
$$

우도 함수는 주어진 파라미터 $$\theta = (\mu,\sigma^2)$$에서 관찰된 데이터 $$𝑋$$가 발생할 확률을 나타냅니다. 데이터가 독립적으로 발생했다고 가정하면, 전체 우도 함수 $$L(\mu,\sigma^2;X)$$는 각 데이터 포인트의 확률 밀도 함수의 곱으로 표현됩니다.

$$
L(\mu, \sigma^2; \mathbf{X}) = \prod_{i=1}^{n} P(x_i ; \mu, \sigma^2)
$$

이를 정규분포의 확률 밀도 함수로 대체하면,

$$
L(\mu, \sigma^2; \mathbf{X}) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
$$

우도 함수를 직접 최대화하는 것은 곱셈으로 인해 복잡하므로, 로그 우도 함수를 사용하여 계산을 단순화합니다. 로그를 취하면 곱셈이 덧셈으로 바뀝니다.

$$
\ell(\mu, \sigma^2; \mathbf{X}) = \log L(\mu, \sigma^2; \mathbf{X}) = \sum_{i=1}^{n} \log \left[\frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)\right]
$$

$$
\ell(\mu, \sigma^2; \mathbf{X}) = \sum_{i=1}^{n} \left[\log \frac{1}{\sqrt{2\pi\sigma^2}} + \log \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)\right]
$$


$$
\ell(\mu, \sigma^2; \mathbf{X}) = \sum_{i=1}^{n} \left[-\frac{1}{2} \log(2\pi\sigma^2) - \frac{(x_i - \mu)^2}{2\sigma^2}\right]
$$

$$ 
\ell(\mu, \sigma^2; \mathbf{X}) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2
$$

이제 이 로그 우도 함수를 원하는 파라미터 $$\theta$$ ($$\mu$$, $$\sigma^2$$)에 대해 최대화하는 값을 찾아야 합니다.

#### (1) 평균 $$\mu$$에 대해 최적화

먼저, 로그 우도 함수 $$\ell(\mu, \sigma^2; \mathbf{X})$$를 $$\mu$$에 대해 미분한 후, 이 값을 0으로 놓아 최적의 $$\mu$$를 찾습니다.

로그 우도 함수를 $$\mu$$에 대해 미분합니다.

$$
\frac{\partial \ell}{\partial \mu} = \frac{\partial}{\partial \mu} \left[ -\frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2 \right]
$$

이제 미분을 계산합니다.

$$
\frac{\partial \ell}{\partial \mu} = -\frac{1}{2\sigma^2} \cdot \left(-2 \sum_{i=1}^{n} (x_i - \mu)\right) = \frac{1}{\sigma^2} \sum_{i=1}^{n} (x_i - \mu)
$$

이 값을 0으로 설정하여 최적의 $$\mu$$를 구합니다.

$$
\frac{1}{\sigma^2} \sum_{i=1}^{n} (x_i - \mu) = 0
$$

이를 풀면 다음과 같은 결과를 얻습니다.

$$
\sum_{i=1}^{n} (x_i - \mu) = 0 \quad \Rightarrow \quad \mu = \frac{1}{n} \sum_{i=1}^{n} x_i
$$

따라서, MLE로 추정된 평균 $$\hat{\mu}$$는 주어진 데이터의 평균입니다.

#### (2) 분산 $$\sigma^2$$에 대해 최적화

이제 로그 우도 함수를 $$\sigma^2$$에 대해 미분한 후, 이 값을 0으로 놓아 최적의 $$\sigma^2$$를 찾습니다.

로그 우도 함수를 $$\sigma^2$$에 대해 미분합니다.

$$
\frac{\partial \ell}{\partial \sigma^2} = \frac{\partial}{\partial \sigma^2} \left[-\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2 \right]
$$

우항의 첫번째 항에서는

$$
\frac{\partial}{\partial \sigma^2} \left[-\frac{n}{2} \log(2\pi\sigma^2)\right] = -\frac{n}{2} \cdot \frac{1}{\sigma^2}
$$

우항의 두번째 항에서는

$$
\frac{\partial}{\partial \sigma^2} \left[- \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2\right] = \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2
$$

따라서, 전체 미분은 다음과 같습니다.

$$
\frac{\partial \ell}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2
$$

이를 0으로 놓고 최적의 $$\sigma^2$$를 구합니다.

$$
-\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2 = 0
$$

이 식을 풀면,

$$
\frac{n}{2\sigma^2} = \frac{1}{2\sigma^4} \sum_{i=1}^{n} (x_i - \mu)^2
$$


$$
n\sigma^2 = \sum_{i=1}^{n} (x_i - \mu)^2
$$

$$
\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2
$$

따라서, 최대우도추정법(MLE)을 통해 추정된 분산 $$\sigma^2$$는 주어진 데이터에 대해 각 데이터 포인트와 평균 $$\mu$$의 차이의 제곱의 평균으로 주어집니다.

### 5. 결론

정규분포에서 MLE를 사용해 평균 $$\mu$$와 분산 $$\sigma^2$$를 추정하는 과정에서, 우리는 로그 우도 함수를 최대화하기 위해 파라미터에 대해 미분을 수행하고, 이를 0으로 설정하여 최적의 값을 찾았습니다.

평균 $$\mu$$는 데이터의 산술 평균으로 추정됩니다. 분산 $$\sigma^2$$는 각 데이터 포인트와 평균 간의 차이 제곱의 평균으로 추정됩니다.

이 결과는 정규분포의 특성과 일치하며, MLE가 매우 유용한 파라미터 추정 방법임을 보여줍니다.


> 참고 자료

- [https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg](https://commons.wikimedia.org/wiki/File:Maximum_de_vraisemblance_dispersion_loi_normale_centree_reduite.svg)
- ['공돌이의 수학정리노트' 최대우도법(Maximum Likelihood Estimation) 소개](https://www.youtube.com/watch?v=XhlfVtGb19c)
- ['공돌이의 수학정리노트' 최대우도법(MLE)](https://angeloyeo.github.io/2020/07/17/MLE.html)