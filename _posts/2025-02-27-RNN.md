---
title: "RNN"
# author:
#   name: Joung min Lim
#   link: https://github.com/min731
date: 2025-02-27 00:00:00 +0900
categories: [AI | 딥러닝, Architecture]
# categories: [AI | 딥러닝 개념, Gradient Descent]
# categories: [AI | 논문 리뷰, Attention is all you need]
# categories: [MLOps | 인프라 개발, Kserve]
# categories: [Life | 일상 이야기, 와플먹으면서 공부하기]
tags: [DeepLearning, RNN]
description: "RNN(Recurrent Neural Network) 구조를 알아봅시다."
image: /assets/img/posts/resize/output/Recurrent_neural_network_unfold.svg.png # 대표 이미지  가로 세로 비율 약 1.91:1 (예: 1200×628px)
math: true
toc: true
---

<div align="center">
  <small>Source: <a href="https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg">https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg</a></small>
</div>

>  *본 게시글은 유튜브 ['메타코드M' 딥러닝 자연어처리 RNN 개념을 30분안에 정리해드립니다ㅣ서울대 AI박사과정](https://www.youtube.com/watch?v=Hn3GHHOXKCE&t=180s&ab_channel=%EB%A9%94%ED%83%80%EC%BD%94%EB%93%9CM) 자료를 참고한 점임을 알립니다.

## RNN에 대해서

### 1. 기본 컨셉
- 재귀적인 (반복되는) 뉴럴 네트워크
- 시간에 따라 weight가 보존되는 네트워크

### 2. 특징
- 시계열 데이터를 처리하기에 좋은 뉴럴 네트워크 구조
- ex) 음성 인식(speech recognition), 번역기(machine translation), 감정 분석(sentiment classification) 등

### 3. RNN vs CNN
- CNN은 이미지의 영역별로 같은 weight를 공유
- RNN은 시간별로 같은 weight를 공유
- 즉, RNN은 과거와 현재에 같은 weight를 공유

### 4. First Order System
- 현재 시간의 상태 ($$x_{t}$$) 가 이전 시간의 상태 ($$x_{t-1}$$) 와 관련이 있다고 가정
- 외부 입력없이 자기 혼자서 돌아간다. => 'Autonomous System'

$$
x_{t} = f(x_{t-1})
$$

- 입력이 있을 수도 있다. => 현재 시간의 상태 ($$x_{t}$$), 이전 시간의 상태 ($$x_{t-1}$$), 현재의 입력 ($$u_{t}$$)
 
 $$x_{t} = f(x_{t-1}, u_{t})$$
 
 
 ex) $$x_{t}$$ : 내일의 날씨, $$x_{t-1}$$ : 오늘의 날씨, $$u_{t}$$ : 구름의 양
 
- $$x_{t}$$를 정확히 예측할 수 없다.
- 관측 가능한 상태만의 모음 => 'State-Space Model'

 $$
 x_{t} = f(x_{t-1}, u_{t})
 $$

 $$
 y_{t} = h(x_{t})
 $$
 
### 5. State-Space Model as RNN(1)

- 'hidden layer'들의 상태를 'hidden state' ($$x_{t}$$)

- 상태($$x_{t}$$)는 이전까지의 상태와, 이전까지의 입력을 모두 대표하는 '압축본'

- 원래 풀고 싶었던 문제
- ex) I ($$u_{0}$$) / like ($$u_{1}$$) / eating ($$u_{2}$$)

 $$
 x_{t} = f(u_{t},u_{t-1},u_{t-2},..., u_{0})
 $$
  
- 대신해서 풀 문제
- ex) I ~ eating ($$x_{t-1}$$,$$u_{t}$$)

 $$
 x_{t} = f(x_{t-1}, u_{t})
 $$

<br>

- state를 거쳐서 오는 'First-order Markov Model'

### 6. State-Space Model as RNN(2)

- 'State-Space Model'에서 근사함수는 2개 ($$f,h$$)

- 입력 ($$u_{t}$$) 과 출력 ($$y_{t}$$) 간의 관계 => 'hidden layer'를 포함한 'Neural Network'

- 함수 $$f$$와 $$h$$를 근사시키기 위해 뉴럴 네트워크를 사용

 $$
 x_{t} = f(x_{t-1}, u_{t})
 $$

 $$
 y_{t} = h(x_{t})
 $$

- 뉴럴 네트워크 셋팅으로 함수 근사

 $$
 x_{t} = \sigma(W_{xx}x_{t-1}+W_{xu}u_{t}+b_{x})
 $$

 $$
 y_{t} = \sigma(W_{yx}x_{t}+b_{y})
 $$

- Parameter matrix는 총 5개 ($$W_{xx},W_{xu},W_{yx},b_{x},b_{y}$$)

- 입력 ($$u_{t}$$) 과 출력 ($$y_{t}$$) 간의 관계 => 'hidden layer'를 포함한 'Neural Network'

 $$
 x_{t} = f(x_{t-1}, u_{t})
 $$

 $$
 y_{t} = h(x_{t})
 $$
 
### 7. RNN: Training

- Back-propagation through time (BPTT)

### 8. RNN: Problem Types

- Many-to-many (기계 번역 등)
  - 'Seq2Seq'의 등장
  - Many-to-one + One-to-Many (번역에 따른 출력 길이가 상이)
  - 입력: "I love deep learning" (영어 문장)
  - 출력: "나는 딥러닝을 좋아한다" (한국어 문장)
- Many-to-one (시계열 예측 등)
  - 최근 30일간의 주식 가격을 보고 내일의 주가 예측
- One-to-many (이미지 캡셔닝, 문장 생성 등)
  - 입력: 개와 고양이가 함께 있는 이미지(단일 입력)
  - 출력: "A dog and a cat are playing together on the grass"(단어 시퀀스)

> 참고 자료
  
- [https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg#Summary](https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg#Summary)
- ['메타코드M' 딥러닝 자연어처리 RNN 개념을 30분안에 정리해드립니다ㅣ서울대 AI박사과정](https://www.youtube.com/watch?v=Hn3GHHOXKCE&t=180s&ab_channel=%EB%A9%94%ED%83%80%EC%BD%94%EB%93%9CM)